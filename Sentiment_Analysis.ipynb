{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mT71jl_6J-L",
        "outputId": "d4a17fcd-c2a4-4378-93d7-49470fa70728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWUT8gAO5iot"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk import PorterStemmer\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report,confusion_matrix\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "\n",
        "\n",
        "from keras.layers import GRU, Bidirectional\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "from keras.layers import SimpleRNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCywFryu5iov"
      },
      "outputs": [],
      "source": [
        "train_pos = os.listdir('train_pos')\n",
        "train_neg= os.listdir('train_neg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxUAuX2q5iov"
      },
      "outputs": [],
      "source": [
        "\n",
        "def read(folder_name,f_list):\n",
        "\n",
        "    data = []\n",
        "    label = []\n",
        "    count=0\n",
        "    for file in f_list:\n",
        "        if count<1000:\n",
        "            with open(folder_name + '/' + file, 'r',encoding=\"utf-8\") as f:\n",
        "                data.append(f.read())\n",
        "                label.append(1 if folder_name == 'train_pos' else 0)\n",
        "            count+=1\n",
        "        else:\n",
        "             break\n",
        "    return data,label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8amK7Zd5iov"
      },
      "outputs": [],
      "source": [
        "train_pos=read('train_pos',train_pos)\n",
        "train_neg=read('train_neg',train_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbf5kAc-5iov"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_pos_df = pd.DataFrame({'data':train_pos[0],'label':train_pos[1]})\n",
        "train_neg_df = pd.DataFrame({'data':train_neg[0],'label':train_neg[1]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhLvN99x5iow"
      },
      "outputs": [],
      "source": [
        "train_df=pd.concat([train_pos_df,train_neg_df],ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaRcOQ7i5iow"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaZtEkc35iow"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.str.replace(r'[\\(\\[].*?[\\)\\]]', '', regex=True)# Rem\n",
        "    text = text.str.replace('[{}]'.format(re.escape(string.punctuation)), '')  # Remove punctuation\n",
        "\n",
        "\n",
        "    clean_text = []\n",
        "    ignore = set(stopwords.words('english'))  # Remove stopwords from text\n",
        "\n",
        "    for i in text:\n",
        "        words = nltk.word_tokenize(i)\n",
        "        words = [word for word in words if word not in ignore and len(word) > 1]\n",
        "        res_text = \" \".join(words)\n",
        "        clean_text.append(res_text)\n",
        "\n",
        "    return clean_text\n",
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbC4TarV5iow",
        "outputId": "091e1547-b475-4c7e-d387-6d81c730b076"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>old_text</th>\n",
              "      <th>review</th>\n",
              "      <th>text</th>\n",
              "      <th>text_lemmatized</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Forest of the Damned starts out as five young ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>forest damned starts five young friends brothe...</td>\n",
              "      <td>forest damned start five young friend brother ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I thought I should qualify my position after r...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>thought qualify position reading reviews movie...</td>\n",
              "      <td>thought qualify position reading review movie ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I don't agree with one of the reviewers who co...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>n't agree one reviewers compared film american...</td>\n",
              "      <td>n't agree one reviewer compared film american ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Los Angeles TV news reporter Jennifer (the bea...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>los angeles tv news reporter jennifer two assi...</td>\n",
              "      <td>los angeles tv news reporter jennifer two assi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After a chance encounter on the train, a young...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chance encounter train young couple spends sin...</td>\n",
              "      <td>chance encounter train young couple spends sin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            old_text review  \\\n",
              "0  Forest of the Damned starts out as five young ...    NaN   \n",
              "1  I thought I should qualify my position after r...    NaN   \n",
              "2  I don't agree with one of the reviewers who co...    NaN   \n",
              "3  Los Angeles TV news reporter Jennifer (the bea...    NaN   \n",
              "4  After a chance encounter on the train, a young...    NaN   \n",
              "\n",
              "                                                text  \\\n",
              "0  forest damned starts five young friends brothe...   \n",
              "1  thought qualify position reading reviews movie...   \n",
              "2  n't agree one reviewers compared film american...   \n",
              "3  los angeles tv news reporter jennifer two assi...   \n",
              "4  chance encounter train young couple spends sin...   \n",
              "\n",
              "                                     text_lemmatized  sentiment  \n",
              "0  forest damned start five young friend brother ...         -1  \n",
              "1  thought qualify position reading review movie ...          1  \n",
              "2  n't agree one reviewer compared film american ...          1  \n",
              "3  los angeles tv news reporter jennifer two assi...          1  \n",
              "4  chance encounter train young couple spends sin...          1  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_df = pd.DataFrame(columns=['old_text', 'review'])\n",
        "processed_df['old_text'] = train_df['data']\n",
        "processed_df['text'] = preprocess_text(train_df['data'])\n",
        "processed_df['text_lemmatized'] = processed_df['text'].apply(lemmatize_text)\n",
        "processed_df['sentiment'] = train_df['label']\n",
        "\n",
        "processed_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZL5ylX_5iox",
        "outputId": "badd4afd-9cc2-45f1-aa92-e3a52526ef2a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>forest damned start five young friend brother ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thought qualify position reading review movie ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>n't agree one reviewer compared film american ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>los angeles tv news reporter jennifer two assi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chance encounter train young couple spends sin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Sentiment\n",
              "0  forest damned start five young friend brother ...         -1\n",
              "1  thought qualify position reading review movie ...          1\n",
              "2  n't agree one reviewer compared film american ...          1\n",
              "3  los angeles tv news reporter jennifer two assi...          1\n",
              "4  chance encounter train young couple spends sin...          1"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analysis_df = pd.DataFrame(columns=['Review', 'Sentiment'])\n",
        "analysis_df['Review'] = processed_df['text_lemmatized'].apply(str)\n",
        "analysis_df['Sentiment'] = processed_df['sentiment']\n",
        "\n",
        "analysis_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82OPNJPs5ioy"
      },
      "outputs": [],
      "source": [
        "analysis_df.to_csv('analysis_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6Ez69Kl5ioy"
      },
      "outputs": [],
      "source": [
        "analysis_df=pd.read_csv(\"analysis_df.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "ksYlIPUyEhqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Default Embedding(RNN)"
      ],
      "metadata": {
        "id": "ESL0g3wldE2S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFzFXzXi5ioy"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(analysis_df['Review'])\n",
        "sequences = tokenizer.texts_to_sequences(analysis_df['Review'])\n",
        "\n",
        "max_sequence_length = max(len(x) for x in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmOz6STS5ioy",
        "outputId": "bcd31e2f-674a-4464-ceb5-5f137c61fdb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (1500, 947)\n",
            "Testing set shape: (500, 947)\n"
          ]
        }
      ],
      "source": [
        "# Splitting the dataset\n",
        "\n",
        "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(padded_sequences, analysis_df['Sentiment'], test_size=0.25, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\",X_train_emb.shape)\n",
        "print(\"Testing set shape:\", X_test_emb.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6Lp8pFP5ioy"
      },
      "outputs": [],
      "source": [
        "X_train_emb=np.array(X_train_emb)\n",
        "y_train_emb=np.array(y_train_emb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TkkhB5i5ioz"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=128))\n",
        "model.add(SimpleRNN(16))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUWgfyQubuSH",
        "outputId": "be9ef644-fbd2-46ed-9320-147d278c0faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 128)         2560384   \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 16)                2320      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2562721 (9.78 MB)\n",
            "Trainable params: 2562721 (9.78 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc3m72rW5ioz",
        "outputId": "611960cb-8825-401c-b2af-ae3c0f1f13dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "9/9 [==============================] - 7s 686ms/step - loss: 0.6657 - accuracy: 0.5956 - val_loss: 0.5953 - val_accuracy: 0.7387\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 6s 600ms/step - loss: 0.3728 - accuracy: 0.9520 - val_loss: 0.4501 - val_accuracy: 0.8560\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 5s 513ms/step - loss: 0.2483 - accuracy: 0.9893 - val_loss: 0.3955 - val_accuracy: 0.8747\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 6s 671ms/step - loss: 0.1920 - accuracy: 0.9911 - val_loss: 0.5407 - val_accuracy: 0.7227\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - 5s 540ms/step - loss: 0.1773 - accuracy: 0.9956 - val_loss: 0.4166 - val_accuracy: 0.8480\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c43ea7731f0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_emb, y_train_emb, epochs=5, batch_size=128, validation_split=0.25)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_emb = np.round(model.predict(X_test_emb))\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test_emb,y_pred_emb) * 100}%\")\n",
        "print(f\"Recall {recall_score(y_test_emb,y_pred_emb) * 100}%\")\n",
        "print(f\"Precision Score: {precision_score(y_test_emb,y_pred_emb) * 100}%\")\n",
        "print(f\"F1 Score: {f1_score(y_test_emb,y_pred_emb) * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ-r5r9CCEbF",
        "outputId": "8768e1ce-c77f-467f-cc4b-f6e97679e4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 2s 91ms/step\n",
            "Accuracy Score: 81.0%\n",
            "Recall 79.08745247148289%\n",
            "Precision Score: 83.87096774193549%\n",
            "F1 Score: 81.40900195694715%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BOW with embedding (RNN)"
      ],
      "metadata": {
        "id": "eQt2wnzIdMBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "\n",
        "X = vectorizer.fit_transform(analysis_df['Review'])\n",
        "\n",
        "X = X.toarray()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, analysis_df['Sentiment'], test_size=0.25, random_state=42)\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "ObKQ1iNKcPXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create RNN model for above dataset and use embedding layer\n",
        "\n",
        "# Create a RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(vectorizer.vocabulary_), output_dim=128))\n",
        "model.add(SimpleRNN(16))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYZ6Xzrkd5xg",
        "outputId": "d87dbe8b-dc32-4768-fbc6-ec79aafade07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 128)         2514304   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 16)                2320      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2516641 (9.60 MB)\n",
            "Trainable params: 2516641 (9.60 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "def load_and_preprocess_data(feature, label):\n",
        "    return feature, label\n",
        "\n",
        "# Create a TensorFlow dataset with batch size 1\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "dataset = dataset.map(load_and_preprocess_data)\n",
        "dataset = dataset.batch(128)\n",
        "# Train the model\n",
        "model.fit(dataset, epochs=5, batch_size=128)\n",
        "# Evaluate the model\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUSkTQSjeK1K",
        "outputId": "d7db822b-709d-4e8b-ba3b-a0367e7b926a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "12/12 [==============================] - 338s 28s/step - loss: 0.6937 - accuracy: 0.4800\n",
            "Epoch 2/5\n",
            "12/12 [==============================] - 346s 29s/step - loss: 0.6925 - accuracy: 0.5093\n",
            "Epoch 3/5\n",
            "12/12 [==============================] - 341s 29s/step - loss: 0.6920 - accuracy: 0.5067\n",
            "Epoch 4/5\n",
            "12/12 [==============================] - 340s 28s/step - loss: 0.6919 - accuracy: 0.5087\n",
            "Epoch 5/5\n",
            "12/12 [==============================] - 341s 29s/step - loss: 0.6914 - accuracy: 0.5067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x797c80fd1e10>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.round(model.predict(X_test))\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test,y_pred) * 100}%\")\n",
        "print(f\"Recall {recall_score(y_test,y_pred) * 100}%\")\n",
        "print(f\"Precision Score: {precision_score(y_test,y_pred) * 100}%\")\n",
        "print(f\"F1 Score: {f1_score(y_test,y_pred) * 100}%\")"
      ],
      "metadata": {
        "id": "NWFbAcKFed_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c724b942-bde0-4ee5-8261-17ad96ef6390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 21s 1s/step\n",
            "Accuracy Score: 49.6%\n",
            "Recall 19.771863117870723%\n",
            "Precision Score: 55.91397849462365%\n",
            "F1 Score: 29.213483146067414%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN wordvec"
      ],
      "metadata": {
        "id": "N5cD-0Oift7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhLOXQjqgilo",
        "outputId": "65fab556-6f77-4ba3-e5b6-fced3005a195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "wSbX13MzQPzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "documents = analysis_df['Review'].apply(simple_preprocess)\n",
        "\n",
        "embedding_dim = 100\n",
        "word2vec_model = Word2Vec(documents, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(analysis_df['Review'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(analysis_df['Review'])\n",
        "\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "X_train_wv, X_test_wv, y_train_wv, y_test_wv = train_test_split(padded_sequences, analysis_df['Sentiment'], test_size=0.25, random_state=42)\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix[i] = word2vec_model.wv[word]"
      ],
      "metadata": {
        "id": "_4PMKlR3SclM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False))\n",
        "model_rnn.add(SimpleRNN(units=64, activation='tanh'))\n",
        "model_rnn.add(Dense(1, activation='sigmoid'))\n",
        "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_rnn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9h8I-JHS3gN",
        "outputId": "17bf7213-fa03-403d-cc60-e642967b392d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 100)         2000300   \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, 64)                10560     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2010925 (7.67 MB)\n",
            "Trainable params: 10625 (41.50 KB)\n",
            "Non-trainable params: 2000300 (7.63 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn.fit(X_train_wv, y_train_wv, epochs=5, batch_size=128)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7zzhxsuTD0T",
        "outputId": "9f92b8c8-ae61-44d6-ea3d-36013300ad24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "12/12 [==============================] - 8s 539ms/step - loss: 0.7076 - accuracy: 0.4880\n",
            "Epoch 2/5\n",
            "12/12 [==============================] - 8s 656ms/step - loss: 0.7150 - accuracy: 0.4847\n",
            "Epoch 3/5\n",
            "12/12 [==============================] - 7s 555ms/step - loss: 0.6934 - accuracy: 0.5093\n",
            "Epoch 4/5\n",
            "12/12 [==============================] - 9s 730ms/step - loss: 0.6939 - accuracy: 0.4967\n",
            "Epoch 5/5\n",
            "12/12 [==============================] - 7s 579ms/step - loss: 0.6934 - accuracy: 0.4967\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c43eb7d5c90>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_wv = np.round(model_rnn.predict(X_test_wv))\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test_wv,y_pred_wv) * 100}%\")\n",
        "print(f\"Recall {recall_score(y_test_wv,y_pred_wv) * 100}%\")\n",
        "print(f\"Precision Score: {precision_score(y_test_wv,y_pred_wv) * 100}%\")\n",
        "print(f\"F1 Score: {f1_score(y_test_wv,y_pred_wv) * 100}%\")"
      ],
      "metadata": {
        "id": "g4rtcUwEgF4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d0bef8-f0e0-495d-8395-e7f9fa5d6aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 2s 92ms/step\n",
            "Accuracy Score: 47.4%\n",
            "Recall 0.0%\n",
            "Precision Score: 0.0%\n",
            "F1 Score: 0.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FastTEXT (RNN)"
      ],
      "metadata": {
        "id": "bOU8WYEce73p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5P3D76rfGar",
        "outputId": "a3d57bf2-f3f7-4a6f-c9fe-ea6ec42ce902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m61.4/68.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4227137 sha256=3c2e2a8787e6a10ca603256c0e2bee95bb3c22911424124e8a4dead72be16b31\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip\n",
        "\n"
      ],
      "metadata": {
        "id": "tkq5EsPFfHcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext"
      ],
      "metadata": {
        "id": "Z_FaLFG-DxGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_df_list = analysis_df['Review'].to_list()\n",
        "analysis_df_list = [i.split(' ') for i in analysis_df_list]"
      ],
      "metadata": {
        "id": "Q4r7ubgVfepJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set()\n",
        "for i in analysis_df_list:\n",
        "    for j in i:\n",
        "        if j not in vocab:\n",
        "            vocab.add(j)"
      ],
      "metadata": {
        "id": "6rPHqrIqhqWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "def load_vectors(fname):\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "    data = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        if tokens[0].lower().strip() in vocab:\n",
        "            data[tokens[0]] = np.array(list(map(float, tokens[1:])))\n",
        "    return data"
      ],
      "metadata": {
        "id": "XR4jcfPBfQhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = load_vectors('/content/wiki-news-300d-1M.vec')"
      ],
      "metadata": {
        "id": "AL_d4Ew1f43v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(analysis_df['Review'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(analysis_df['Review'])\n",
        "\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(padded_sequences, analysis_df['Sentiment'], test_size=0.25, random_state=42)\n"
      ],
      "metadata": {
        "id": "hNNFoQbWgYju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in embedding:\n",
        "        embedding_matrix[i] = embedding[word]"
      ],
      "metadata": {
        "id": "5ptEZ80TjNm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn = Sequential()\n",
        "model_rnn.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False))\n",
        "model_rnn.add(SimpleRNN(units=64, activation='tanh'))\n",
        "model_rnn.add(Dense(1, activation='sigmoid'))\n",
        "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_rnn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjloMO3-jie8",
        "outputId": "b0ea3f4c-6acd-4f5f-fbfb-9fe491f90a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, None, 300)         6000900   \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 64)                23360     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6024325 (22.98 MB)\n",
            "Trainable params: 23425 (91.50 KB)\n",
            "Non-trainable params: 6000900 (22.89 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_rnn.fit(X_train_ft, y_train_ft, epochs=5, batch_size=128, validation_split=0.25)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNdnbzyXjxXn",
        "outputId": "e6bea115-7637-4965-b9dc-9cfef4d59ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "9/9 [==============================] - 12s 829ms/step - loss: 0.7017 - accuracy: 0.4987 - val_loss: 0.7006 - val_accuracy: 0.4880\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 13s 2s/step - loss: 0.6954 - accuracy: 0.5076 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.6909 - accuracy: 0.5316 - val_loss: 0.6920 - val_accuracy: 0.5200\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 10s 1s/step - loss: 0.6935 - accuracy: 0.4889 - val_loss: 0.6947 - val_accuracy: 0.4987\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - 13s 1s/step - loss: 0.6936 - accuracy: 0.5200 - val_loss: 0.6921 - val_accuracy: 0.5440\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c43eb63bd60>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ft = np.round(model_rnn.predict(X_test_ft))\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test_ft,y_pred_ft) * 100}%\")\n",
        "print(f\"Recall {recall_score(y_test_ft,y_pred_ft) * 100}%\")\n",
        "print(f\"Precision Score: {precision_score(y_test_ft,y_pred_ft) * 100}%\")\n",
        "print(f\"F1 Score: {f1_score(y_test_ft,y_pred_ft) * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NEC9Sfej1FY",
        "outputId": "4e5ce0b0-6916-44b3-b416-8a915a5bcebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 2s 101ms/step\n",
            "Accuracy Score: 47.4%\n",
            "Recall 32.69961977186312%\n",
            "Precision Score: 50.0%\n",
            "F1 Score: 39.54022988505747%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "4JETljEAEvJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM with defaut embedding"
      ],
      "metadata": {
        "id": "GeS7v5DOEoq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=128))\n",
        "model.add(LSTM(16))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJGgnkRvEnB9",
        "outputId": "88196bba-a7ea-446a-dc30-4418a4ccde62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, None, 128)         2560384   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 16)                9280      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2569681 (9.80 MB)\n",
            "Trainable params: 2569681 (9.80 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_emb, y_train_emb, epochs=5, batch_size=128, validation_split=0.25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbJbAGBzE_2s",
        "outputId": "66878ffd-b585-4a5a-bb42-d9a55ca91fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "9/9 [==============================] - 11s 935ms/step - loss: 0.6908 - accuracy: 0.5458 - val_loss: 0.6897 - val_accuracy: 0.5493\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.6712 - accuracy: 0.7867 - val_loss: 0.6818 - val_accuracy: 0.6320\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 7s 756ms/step - loss: 0.6370 - accuracy: 0.9013 - val_loss: 0.6628 - val_accuracy: 0.6853\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 8s 907ms/step - loss: 0.5630 - accuracy: 0.9351 - val_loss: 0.6077 - val_accuracy: 0.7360\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.4212 - accuracy: 0.9600 - val_loss: 0.4623 - val_accuracy: 0.8800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c43c9a38730>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_emb = np.round(model.predict(X_test_emb))\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test_emb,y_pred_emb) * 100}%\")\n",
        "print(f\"Recall {recall_score(y_test_emb,y_pred_emb) * 100}%\")\n",
        "print(f\"Precision Score: {precision_score(y_test_emb,y_pred_emb) * 100}%\")\n",
        "print(f\"F1 Score: {f1_score(y_test_emb,y_pred_emb) * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwBmgkTzFB9G",
        "outputId": "fb19de3c-1119-4e7f-f150-bb6bbd438b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 3s 137ms/step\n",
            "Accuracy Score: 80.80000000000001%\n",
            "Recall 72.24334600760456%\n",
            "Precision Score: 89.2018779342723%\n",
            "F1 Score: 79.83193277310924%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM with word2vec"
      ],
      "metadata": {
        "id": "Gz1VhEWpFWTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False))\n",
        "model.add(LSTM(units=64, activation='tanh'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd4hR-erFTwZ",
        "outputId": "40c87d61-631a-4b6e-d0ac-53b7e677e63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, None, 300)         6000900   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                93440     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6094405 (23.25 MB)\n",
            "Trainable params: 93505 (365.25 KB)\n",
            "Non-trainable params: 6000900 (22.89 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_wv, y_train_wv, epochs=5, batch_size=128)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJcsNNOOFnI8",
        "outputId": "b027ab99-a805-4078-8889-1f30249a34b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "12/12 [==============================] - 49s 3s/step - loss: 0.6933 - accuracy: 0.4940\n",
            "Epoch 2/5\n",
            "12/12 [==============================] - 45s 4s/step - loss: 0.6931 - accuracy: 0.5087\n",
            "Epoch 3/5\n",
            "12/12 [==============================] - 34s 3s/step - loss: 0.6932 - accuracy: 0.5087\n",
            "Epoch 4/5\n",
            "12/12 [==============================] - 27s 2s/step - loss: 0.6930 - accuracy: 0.5087\n",
            "Epoch 5/5\n",
            "12/12 [==============================] - 27s 2s/step - loss: 0.6931 - accuracy: 0.5087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c43d200cee0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_wv = np.round(model.predict(X_test_wv))\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test_wv,y_pred_wv) * 100}%\")\n",
        "print(f\"Recall {recall_score(y_test_wv,y_pred_wv) * 100}%\")\n",
        "print(f\"Precision Score: {precision_score(y_test_wv,y_pred_wv) * 100}%\")\n",
        "print(f\"F1 Score: {f1_score(y_test_wv,y_pred_wv) * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziCzTq1lF0fU",
        "outputId": "7a8e2ecb-029d-4d9f-fd68-04888972aade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 10s 581ms/step\n",
            "Accuracy Score: 47.4%\n",
            "Recall 0.0%\n",
            "Precision Score: 0.0%\n",
            "F1 Score: 0.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM WITH Fasttext"
      ],
      "metadata": {
        "id": "yH78sSaVF4mT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False))\n",
        "model.add(SimpleRNN(units=64, activation='tanh'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iyxApChGEEy",
        "outputId": "ce8a197a-d54c-4ff0-a1c4-4a27338658a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, None, 300)         6000900   \n",
            "                                                                 \n",
            " simple_rnn_6 (SimpleRNN)    (None, 64)                23360     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6024325 (22.98 MB)\n",
            "Trainable params: 23425 (91.50 KB)\n",
            "Non-trainable params: 6000900 (22.89 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(X_train_ft, y_train_ft, epochs=5, batch_size=128, validation_split=0.25)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-VrFVDbGlqY",
        "outputId": "30d07616-7e7d-4e9a-b6ec-b6639c98f5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "9/9 [==============================] - 23s 2s/step - loss: 0.7039 - accuracy: 0.5013 - val_loss: 0.6921 - val_accuracy: 0.5387\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 9s 985ms/step - loss: 0.7030 - accuracy: 0.4978 - val_loss: 0.6873 - val_accuracy: 0.5707\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 14s 2s/step - loss: 0.6932 - accuracy: 0.5049 - val_loss: 0.6974 - val_accuracy: 0.4640\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 8s 839ms/step - loss: 0.6930 - accuracy: 0.5164 - val_loss: 0.6941 - val_accuracy: 0.4987\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.6931 - accuracy: 0.5227 - val_loss: 0.6919 - val_accuracy: 0.5307\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c43d1b22d40>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ft = np.round(model_rnn.predict(X_test_ft))\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test_ft,y_pred_ft) * 100}%\")\n",
        "print(f\"Recall {recall_score(y_test_ft,y_pred_ft) * 100}%\")\n",
        "print(f\"Precision Score: {precision_score(y_test_ft,y_pred_ft) * 100}%\")\n",
        "print(f\"F1 Score: {f1_score(y_test_ft,y_pred_ft) * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw-sIXPoGxxs",
        "outputId": "fc5b994e-c262-46ab-9842-b1069a3e5c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 7s 388ms/step\n",
            "Accuracy Score: 47.4%\n",
            "Recall 0.0%\n",
            "Precision Score: 0.0%\n",
            "F1 Score: 0.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ],
      "metadata": {
        "id": "9TuHSI9FHSrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU WITH default embedding"
      ],
      "metadata": {
        "id": "biUBmeFAHVjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=128))\n",
        "model.add(GRU(16))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsm05efrHORi",
        "outputId": "9605d931-cd61-437b-aedc-b830eb4d51b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, None, 128)         2560384   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 16)                7008      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2567409 (9.79 MB)\n",
            "Trainable params: 2567409 (9.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_emb, y_train_emb, epochs=5, batch_size=128)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_QfFg6aHRCM",
        "outputId": "35cd2bbc-93a3-4931-bd41-fad032821352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "12/12 [==============================] - 13s 716ms/step - loss: 0.6914 - accuracy: 0.5360\n",
            "Epoch 2/5\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.6639 - accuracy: 0.7980\n",
            "Epoch 3/5\n",
            "12/12 [==============================] - 10s 803ms/step - loss: 0.6159 - accuracy: 0.8793\n",
            "Epoch 4/5\n",
            "12/12 [==============================] - 15s 1s/step - loss: 0.5289 - accuracy: 0.9007\n",
            "Epoch 5/5\n",
            "12/12 [==============================] - 8s 654ms/step - loss: 0.3980 - accuracy: 0.9220\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c43c9a39270>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_emb = np.round(model.predict(X_test_emb))\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test_emb,y_pred_emb) * 100}%\")\n",
        "print(f\"Recall {recall_score(y_test_emb,y_pred_emb) * 100}%\")\n",
        "print(f\"Precision Score: {precision_score(y_test_emb,y_pred_emb) * 100}%\")\n",
        "print(f\"F1 Score: {f1_score(y_test_emb,y_pred_emb) * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvWmiup4HweO",
        "outputId": "e1680b0d-0237-40c4-e4c8-de8745d0a6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 1s 63ms/step\n",
            "Accuracy Score: 67.60000000000001%\n",
            "Recall 65.39923954372624%\n",
            "Precision Score: 70.78189300411523%\n",
            "F1 Score: 67.98418972332016%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2TWmO_eH43-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ESL0g3wldE2S",
        "eQt2wnzIdMBU",
        "N5cD-0Oift7p",
        "bOU8WYEce73p",
        "Gz1VhEWpFWTe"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}